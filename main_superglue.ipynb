{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "f3cwQ4zBSUog"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in ./.local/lib/python3.10/site-packages (2.20.0)\n",
      "Requirement already satisfied: multiprocess in ./.local/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./.local/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.local/lib/python3.10/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./.local/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: packaging in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from datasets) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./.local/lib/python3.10/site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: pandas in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from datasets) (2.2.0)\n",
      "Requirement already satisfied: aiohttp in ./.local/lib/python3.10/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: filelock in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from datasets) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in ./.local/lib/python3.10/site-packages (from datasets) (0.23.5)\n",
      "Requirement already satisfied: pyarrow-hotfix in ./.local/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: xxhash in ./.local/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in ./.local/lib/python3.10/site-packages (from datasets) (2024.5.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.15)\n",
      "Requirement already satisfied: pytz>=2020.1 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: evaluate in ./.local/lib/python3.10/site-packages (0.4.2)\n",
      "Requirement already satisfied: xxhash in ./.local/lib/python3.10/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in ./.local/lib/python3.10/site-packages (from evaluate) (0.23.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./.local/lib/python3.10/site-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: packaging in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from evaluate) (23.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./.local/lib/python3.10/site-packages (from evaluate) (4.66.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from evaluate) (1.24.3)\n",
      "Requirement already satisfied: dill in ./.local/lib/python3.10/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from evaluate) (2.2.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in ./.local/lib/python3.10/site-packages (from evaluate) (2.20.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in ./.local/lib/python3.10/site-packages (from evaluate) (2024.5.0)\n",
      "Requirement already satisfied: multiprocess in ./.local/lib/python3.10/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: pyarrow-hotfix in ./.local/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.local/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0)\n",
      "Requirement already satisfied: aiohttp in ./.local/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n",
      "Requirement already satisfied: filelock in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from pandas->evaluate) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
      "Requirement already satisfied: six>=1.5 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in ./.local/lib/python3.10/site-packages (4.40.2)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./.local/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.local/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.local/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: filelock in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in ./.local/lib/python3.10/site-packages (from transformers) (0.23.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.12.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: adapters in ./.local/lib/python3.10/site-packages (0.2.2)\n",
      "Requirement already satisfied: transformers~=4.40.2 in ./.local/lib/python3.10/site-packages (from adapters) (4.40.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.10/site-packages (from transformers~=4.40.2->adapters) (2024.5.15)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from transformers~=4.40.2->adapters) (6.0)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.10/site-packages (from transformers~=4.40.2->adapters) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.local/lib/python3.10/site-packages (from transformers~=4.40.2->adapters) (4.66.4)\n",
      "Requirement already satisfied: filelock in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from transformers~=4.40.2->adapters) (3.9.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./.local/lib/python3.10/site-packages (from transformers~=4.40.2->adapters) (0.19.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from transformers~=4.40.2->adapters) (23.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in ./.local/lib/python3.10/site-packages (from transformers~=4.40.2->adapters) (0.23.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from transformers~=4.40.2->adapters) (1.24.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.local/lib/python3.10/site-packages (from transformers~=4.40.2->adapters) (0.4.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers~=4.40.2->adapters) (4.12.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers~=4.40.2->adapters) (2024.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from requests->transformers~=4.40.2->adapters) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from requests->transformers~=4.40.2->adapters) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from requests->transformers~=4.40.2->adapters) (2024.2.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from requests->transformers~=4.40.2->adapters) (1.26.15)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: accelerate==0.30 in ./.local/lib/python3.10/site-packages (0.30.0)\n",
      "Requirement already satisfied: huggingface-hub in ./.local/lib/python3.10/site-packages (from accelerate==0.30) (0.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from accelerate==0.30) (23.0)\n",
      "Requirement already satisfied: psutil in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from accelerate==0.30) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from accelerate==0.30) (6.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./.local/lib/python3.10/site-packages (from accelerate==0.30) (0.4.3)\n",
      "Requirement already satisfied: torch>=1.10.0 in ./.local/lib/python3.10/site-packages (from accelerate==0.30) (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from accelerate==0.30) (1.24.3)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30) (12.1.105)\n",
      "Requirement already satisfied: filelock in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30) (3.9.0)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30) (3.3)\n",
      "Requirement already satisfied: fsspec in ./.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30) (2024.5.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in ./.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30) (2.20.5)\n",
      "Requirement already satisfied: triton==2.3.1 in ./.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30) (2.3.1)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30) (11.4.5.107)\n",
      "Requirement already satisfied: jinja2 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30) (12.1.105)\n",
      "Requirement already satisfied: sympy in ./.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30) (1.13.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30) (12.1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30) (4.12.2)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.local/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.30) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.30) (12.5.82)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm>=4.42.1 in ./.local/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.30) (4.66.4)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.30) (2.32.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.30) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.30) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.30) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.30) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /storage/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.30) (2024.2.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.30) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install datasets\n",
    "!pip3 install evaluate\n",
    "!pip3 install transformers\n",
    "!pip3 install adapters\n",
    "!pip3 install accelerate==0.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "7RJs70ZZjimj"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "from dataclasses import dataclass, field\n",
    "import pandas as pd\n",
    "from typing import Optional\n",
    "\n",
    "import datasets\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "import evaluate\n",
    "import transformers\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    PretrainedConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    "    set_seed,\n",
    ")\n",
    "from adapters import AdapterArguments, AdapterTrainer, AutoAdapterModel, setup_adapter_training, AdapterConfig\n",
    "from transformers import TrainerCallback\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from transformers.utils import check_min_version\n",
    "from transformers.utils.versions import require_version\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "agqkSluJcFZU"
   },
   "outputs": [],
   "source": [
    "task_to_keys = {\n",
    "    \"boolq\": (\"question\", \"passage\"),\n",
    "    \"cb\": (\"premise\", \"hypothesis\"),\n",
    "    \"copa\": (\"premise\", \"choice1\", \"choice2\"),\n",
    "    \"multirc\": (\"paragraph\", \"question\"),\n",
    "    \"record\": (\"passage\", \"query\"),\n",
    "    \"rte\": (\"premise\", \"hypothesis\"),\n",
    "    \"wic\": (\"sentence1\", \"sentence2\"),\n",
    "    \"wsc\": (\"text\", None),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "FZ5aXA4acJBk"
   },
   "outputs": [],
   "source": [
    "def filter_unused_args(args):\n",
    "    filtered_args = []\n",
    "    for arg in args:\n",
    "        if not arg.startswith(\"-f\") and not (arg.endswith(\".json\") or arg.endswith(\".py\")):\n",
    "            filtered_args.append(arg)\n",
    "    return filtered_args\n",
    "@dataclass\n",
    "class DataTrainingArguments:\n",
    "    task_name: Optional[str] = field(\n",
    "        default='boolq',\n",
    "        metadata={\"help\": \"The name of the task to train on: \" + \", \".join(task_to_keys.keys())},\n",
    "    )\n",
    "    dataset_name: Optional[str] = field(\n",
    "        default='super_glue', metadata={\"help\": \"The name of the dataset to use (via the datasets library).\"}\n",
    "    )\n",
    "    dataset_config_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"The configuration name of the dataset to use (via the datasets library).\"}\n",
    "    )\n",
    "    max_seq_length: int = field(\n",
    "        default=128,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"The maximum total input sequence length after tokenization. Sequences longer \"\n",
    "                \"than this will be truncated, sequences shorter will be padded.\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "    overwrite_cache: bool = field(\n",
    "        default=False, metadata={\"help\": \"Overwrite the cached preprocessed datasets or not.\"}\n",
    "    )\n",
    "    pad_to_max_length: bool = field(\n",
    "        default=True,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"Whether to pad all samples to `max_seq_length`. \"\n",
    "                \"If False, will pad the samples dynamically when batching to the maximum length in the batch.\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "    max_train_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"For debugging purposes or quicker training, truncate the number of training examples to this \"\n",
    "                \"value if set.\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "    max_eval_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"For debugging purposes or quicker training, truncate the number of evaluation examples to this \"\n",
    "                \"value if set.\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "    max_predict_samples: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"For debugging purposes or quicker training, truncate the number of prediction examples to this \"\n",
    "                \"value if set.\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "    train_file: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"A csv or a json file containing the training data.\"}\n",
    "    )\n",
    "    validation_file: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"A csv or a json file containing the validation data.\"}\n",
    "    )\n",
    "    test_file: Optional[str] = field(default=None, metadata={\"help\": \"A csv or a json file containing the test data.\"})\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if self.task_name is not None:\n",
    "            self.task_name = self.task_name.lower()\n",
    "            if self.task_name not in task_to_keys.keys():\n",
    "                raise ValueError(\"Unknown task, you should pick one in \" + \",\".join(task_to_keys.keys()))\n",
    "        elif self.dataset_name is not None:\n",
    "            pass\n",
    "        elif self.train_file is None or self.validation_file is None:\n",
    "            raise ValueError(\"Need either a GLUE task, a training/validation file or a dataset name.\")\n",
    "        else:\n",
    "            train_extension = self.train_file.split(\".\")[-1]\n",
    "            assert train_extension in [\"csv\", \"json\"], \"`train_file` should be a csv or a json file.\"\n",
    "            validation_extension = self.validation_file.split(\".\")[-1]\n",
    "            assert (\n",
    "                validation_extension == train_extension\n",
    "            ), \"`validation_file` should have the same extension (csv or json) as `train_file`.\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelArguments:\n",
    "    model_name_or_path: str = field(\n",
    "        default='distilbert/distilbert-base-uncased',\n",
    "        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n",
    "    )\n",
    "    config_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n",
    "    )\n",
    "    tokenizer_name: Optional[str] = field(\n",
    "        default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n",
    "    )\n",
    "    cache_dir: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Where do you want to store the pretrained models downloaded from huggingface.co\"},\n",
    "    )\n",
    "    use_fast_tokenizer: bool = field(\n",
    "        default=True,\n",
    "        metadata={\"help\": \"Whether to use one of the fast tokenizers (backed by the tokenizers library) or not.\"},\n",
    "    )\n",
    "    model_revision: str = field(\n",
    "        default=\"main\",\n",
    "        metadata={\"help\": \"The specific model version to use (can be a branch name, tag name, or commit id).\"},\n",
    "    )\n",
    "    use_auth_token: bool = field(\n",
    "        default=False,\n",
    "        metadata={\n",
    "            \"help\": (\n",
    "                \"Will use the token generated when running `huggingface-cli login` (necessary to use this script \"\n",
    "                \"with private models).\"\n",
    "            )\n",
    "        },\n",
    "    )\n",
    "    ignore_mismatched_sizes: bool = field(\n",
    "        default=False,\n",
    "        metadata={\"help\": \"Will enable loading a pretrained model whose head dimensions are different.\"},\n",
    "    )\n",
    "@dataclass\n",
    "class TrainingArguments(transformers.TrainingArguments):\n",
    "    output_dir: str = field(\n",
    "        default=\"./results\",\n",
    "        metadata={\"help\": \"The output directory where the model predictions and checkpoints will be written.\"}\n",
    "    )\n",
    "    adapter: str = field(\n",
    "        default=True,\n",
    "        metadata={\"help\": \"Whether you wanna train adapter or fine-tune\"}\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "parser = HfArgumentParser((ModelArguments, DataTrainingArguments, TrainingArguments))\n",
    "filtered_args = filter_unused_args(sys.argv)\n",
    "model_args, data_args, training_args = parser.parse_args_into_dataclasses(args=filtered_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "mS7f3zqzcQzt"
   },
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO if training_args.local_rank in [-1, 0] else logging.WARN)\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "nD1eeJS5cT0h"
   },
   "outputs": [],
   "source": [
    "### Set Hyperparams Here\n",
    "model_args.model_name_or_path = 'distilbert/distilbert-base-uncased'\n",
    "data_args.dataset_name = 'super_glue'\n",
    "data_args.task_name = 'boolq'\n",
    "training_args.adapter = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from adapters import BnConfig, PrefixTuningConfig, MAMConfig, CompacterPlusPlusConfig, UniPELTConfig,\\\n",
    "                    IA3Config, LoRAConfig, PromptTuningConfig,\\\n",
    "                    ConfigUnion\n",
    "\n",
    "string_to_config = {'seq_bn': BnConfig(mh_adapter=True, output_adapter=True, reduction_factor=16, non_linearity=\"relu\"),\n",
    "                   \"prefix_tuning\": PrefixTuningConfig(flat=False, prefix_length=30),\n",
    "                   \"mam_adapter\": MAMConfig(),\n",
    "                   \"compacter_plusplus\": CompacterPlusPlusConfig(),\n",
    "                   \"unipelt\":UniPELTConfig(),\n",
    "                   \"lora\": LoRAConfig(r=8, alpha=16),\n",
    "                   \"seq_bn_16_2_relu\": ConfigUnion(\n",
    "                            BnConfig(mh_adapter=True, output_adapter=False, reduction_factor=16, non_linearity=\"relu\"),\n",
    "                            BnConfig(mh_adapter=False, output_adapter=True, reduction_factor=2, non_linearity=\"relu\"),\n",
    "                        ),\n",
    "                    \"seq_bn_16_2_tanh\": ConfigUnion(\n",
    "                            BnConfig(mh_adapter=True, output_adapter=False, reduction_factor=16, non_linearity=\"tanh\"),\n",
    "                            BnConfig(mh_adapter=False, output_adapter=True, reduction_factor=2, non_linearity=\"tanh\"),\n",
    "                        ),\n",
    "                    \"ia3\":IA3Config(),\n",
    "                    'prompt_tuning': PromptTuningConfig(prompt_length=10)\n",
    "#                     'loreft':ReftConfig(layers=\"all\", prefix_positions=3, suffix_positions=0, r=1, orthogonality=True),\n",
    "#                     'noreft':ReftConfig(layers=\"all\", prefix_positions=3, suffix_positions=0, r=1, orthogonality=False),\n",
    "#                     'direft':ReftConfig(layers=\"all\", prefix_positions=3, suffix_positions=0, r=1, orthogonality=False, subtract_projection=False)\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    args = (\n",
    "        (examples[sentence1_key],) if sentence2_key is None else (examples[sentence1_key], examples[sentence2_key])\n",
    "    )\n",
    "    result = tokenizer(*args, padding=padding, max_length=max_seq_length, truncation=True)\n",
    "    if label_to_id is not None and \"label\" in examples:\n",
    "        result[\"label\"] = [(label_to_id[l] if l != -1 else -1) for l in examples[\"label\"]]\n",
    "    return result\n",
    "\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
    "    preds = np.squeeze(preds) if is_regression else np.argmax(preds, axis=1)\n",
    "    if data_args.task_name is not None:\n",
    "        result = metric.compute(predictions=preds, references=p.label_ids)\n",
    "        if len(result) > 1:\n",
    "            result[\"combined_score\"] = np.mean(list(result.values())).item()\n",
    "        return result\n",
    "    elif is_regression:\n",
    "        return {\"mse\": ((preds - p.label_ids) ** 2).mean().item()}\n",
    "    else:\n",
    "        return {\"accuracy\": (preds == p.label_ids).astype(np.float32).mean().item()}\n",
    "    \n",
    "def preprocess_data(raw_datasets,data_args,model,is_regression,num_labels,label_list,tokenizer):\n",
    "    raw_datasets = raw_datasets.map(\n",
    "        preprocess_function,\n",
    "        batched=True,\n",
    "        load_from_cache_file=not data_args.overwrite_cache,\n",
    "        desc=\"Running tokenizer on dataset\",\n",
    "    )\n",
    "\n",
    "    train_dataset = raw_datasets[\"train\"]\n",
    "    if data_args.max_train_samples is not None:\n",
    "        max_train_samples = min(len(train_dataset), data_args.max_train_samples)\n",
    "        train_dataset = train_dataset.select(range(max_train_samples))\n",
    "\n",
    "    eval_dataset = raw_datasets[\"validation_matched\" if data_args.task_name == \"mnli\" else \"validation\"]\n",
    "    if data_args.max_eval_samples is not None:\n",
    "        max_eval_samples = min(len(eval_dataset), data_args.max_eval_samples)\n",
    "        eval_dataset = eval_dataset.select(range(max_eval_samples))\n",
    "\n",
    "    predict_dataset = raw_datasets[\"test_matched\" if data_args.task_name == \"mnli\" else \"test\"]\n",
    "    if data_args.max_predict_samples is not None:\n",
    "        max_predict_samples = min(len(predict_dataset), data_args.max_predict_samples)\n",
    "        predict_dataset = predict_dataset.select(range(max_predict_samples))\n",
    "\n",
    "    metric = evaluate.load(\"super_glue\", data_args.task_name)\n",
    "\n",
    "\n",
    "    data_collator = default_data_collator\n",
    "    \n",
    "    return train_dataset, eval_dataset, predict_dataset, data_args, data_collator, model, metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "5wBH73EviIzB"
   },
   "outputs": [],
   "source": [
    "class MetricsCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.metrics = []\n",
    "\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs is not None:\n",
    "            self.metrics.append(logs.copy())\n",
    "            \n",
    "def run_model(model,training_args,train_dataset,eval_dataset,tokenizer,data_collator):\n",
    "    training_args.evaluation_strategy=\"epoch\"\n",
    "    trainer_class = AdapterTrainer if training_args.adapter else Trainer\n",
    "    metrics_callback = MetricsCallback()\n",
    "    trainer = trainer_class(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        callbacks=[metrics_callback]\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    checkpoint = get_last_checkpoint(training_args.output_dir) if training_args.resume_from_checkpoint is None else training_args.resume_from_checkpoint\n",
    "    train_result = trainer.train()\n",
    "    df_metrics = pd.DataFrame(metrics_callback.metrics)\n",
    "\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    metrics = train_result.metrics\n",
    "    max_train_samples = data_args.max_train_samples if data_args.max_train_samples is not None else len(train_dataset)\n",
    "    metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n",
    "    metrics[\"training_time\"] = training_time\n",
    "\n",
    "    trainer.save_model()  # Saves the tokenizer too for easy upload\n",
    "\n",
    "    trainer.log_metrics(\"train\", metrics)\n",
    "    trainer.log_metrics(\"eval\", metrics)\n",
    "    trainer.save_metrics(\"train\", metrics)\n",
    "    trainer.save_metrics(\"eval\", metrics)\n",
    "    trainer.save_state()\n",
    "    \n",
    "    return trainer, train_result, df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_iteration(model_string,data_args,training_args):\n",
    "    global sentence1_key, sentence2_key,padding,label_to_id,tokenizer,max_seq_length,is_regression,metric\n",
    "    training_args.adapter_type = model_string\n",
    "    raw_datasets = load_dataset(\n",
    "        data_args.dataset_name,\n",
    "        data_args.task_name,\n",
    "        cache_dir=model_args.cache_dir,\n",
    "        use_auth_token=model_args.use_auth_token\n",
    "    )\n",
    "    is_regression = data_args.task_name == \"stsb\"\n",
    "    if not is_regression:\n",
    "        label_list = raw_datasets[\"train\"].features[\"label\"].names\n",
    "        num_labels = len(label_list)\n",
    "    else:\n",
    "        num_labels = 1\n",
    "\n",
    "    config = AutoConfig.from_pretrained(\n",
    "        model_args.model_name_or_path,\n",
    "        num_labels=num_labels,\n",
    "        finetuning_task=data_args.task_name,\n",
    "        cache_dir=model_args.cache_dir,\n",
    "        use_auth_token=model_args.use_auth_token,\n",
    "    )\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        model_args.model_name_or_path,\n",
    "        cache_dir=model_args.cache_dir,\n",
    "        use_fast=model_args.use_fast_tokenizer,\n",
    "        use_auth_token=model_args.use_auth_token\n",
    "    )\n",
    "    if training_args.adapter:\n",
    "        model = AutoAdapterModel.from_pretrained(\n",
    "            model_args.model_name_or_path,\n",
    "            from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\n",
    "            config=config,\n",
    "            cache_dir=model_args.cache_dir,\n",
    "            use_auth_token=model_args.use_auth_token,\n",
    "            ignore_mismatched_sizes=model_args.ignore_mismatched_sizes\n",
    "        )\n",
    "        model.add_classification_head(\n",
    "        data_args.dataset_name,\n",
    "        num_labels=num_labels,\n",
    "        id2label={i: v for i, v in enumerate(label_list)} if not is_regression else None,\n",
    "        )\n",
    "        adapter_config_kwargs = {}\n",
    "        adapter_load_kwargs = {}\n",
    "        model.add_adapter(training_args.adapter_type, config=string_to_config[training_args.adapter_type])\n",
    "        if training_args.adapter_type=='prefix_tuning':\n",
    "            model.eject_prefix_tuning(\"prefix_tuning\")\n",
    "        model.train_adapter([training_args.adapter_type])\n",
    "        model.set_active_adapters(training_args.adapter_type)\n",
    "    else:\n",
    "        model = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_args.model_name_or_path,\n",
    "            config=config,\n",
    "            cache_dir=model_args.cache_dir,\n",
    "            use_auth_token=model_args.use_auth_token,\n",
    "            ignore_mismatched_sizes=model_args.ignore_mismatched_sizes\n",
    "        )\n",
    "    sentence1_key, sentence2_key = task_to_keys[data_args.task_name]\n",
    "    padding = \"max_length\" if data_args.pad_to_max_length else False\n",
    "    label_to_id = None\n",
    "    if (\n",
    "        model.config.label2id != PretrainedConfig(num_labels=num_labels).label2id\n",
    "        and data_args.task_name is not None\n",
    "        and not is_regression\n",
    "    ):\n",
    "        label_name_to_id = {k.lower(): v for k, v in model.config.label2id.items()}\n",
    "        if list(sorted(label_name_to_id.keys())) == list(sorted(label_list)):\n",
    "            label_to_id = {i: int(label_name_to_id[label_list[i]]) for i in range(num_labels)}\n",
    "        else:\n",
    "            logger.warning(\n",
    "                \"Your model seems to have been trained with labels, but they don't match the dataset: \",\n",
    "                f\"model labels: {list(sorted(label_name_to_id.keys()))}, dataset labels: {list(sorted(label_list))}.\"\n",
    "                \"\\nIgnoring the model labels as a result.\",\n",
    "            )\n",
    "    elif data_args.task_name is None and not is_regression:\n",
    "        label_to_id = {v: i for i, v in enumerate(label_list)}\n",
    "    if label_to_id is not None:\n",
    "        model.config.label2id = label_to_id\n",
    "        model.config.id2label = {id: label for label, id in config.label2id.items()}\n",
    "    elif data_args.task_name is not None and not is_regression:\n",
    "        model.config.label2id = {l: i for i, l in enumerate(label_list)}\n",
    "        model.config.id2label = {id: label for label, id in config.label2id.items()}\n",
    "\n",
    "    max_seq_length = min(data_args.max_seq_length, tokenizer.model_max_length)\n",
    "\n",
    "    train_dataset, eval_dataset, predict_dataset, data_args, data_collator, model, metric = \\\n",
    "                            preprocess_data(raw_datasets,data_args,model,is_regression,num_labels,label_list,tokenizer)\n",
    "    trainer, train_result, df_metrics = run_model(model,training_args,train_dataset,eval_dataset,tokenizer,data_collator)\n",
    "    eval_metrics = trainer.evaluate(eval_dataset=eval_dataset)\n",
    "    eval_accuracy = eval_metrics['eval_accuracy']\n",
    "\n",
    "    na_loss_ix = list(df_metrics[df_metrics['loss'].isna()].index)\n",
    "    true_loss_ix = [i-1 for i in na_loss_ix]\n",
    "    df_metrics.iloc[na_loss_ix,0] = df_metrics.iloc[true_loss_ix,0]\n",
    "    df_metrics = df_metrics[~df_metrics.eval_loss.isna()].reset_index(drop=True)\n",
    "    fig = plt.figure(1)\n",
    "    plt.title('Epoch vs Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(df_metrics.loss, label=\"Train Loss\")\n",
    "    plt.plot(df_metrics.eval_loss, label=\"Eval Loss\")\n",
    "    leg = plt.legend(loc='lower left')\n",
    "    \n",
    "    return [eval_accuracy,fig]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hice1/maleem3/.local/lib/python3.10/site-packages/datasets/load.py:2554: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
      "  warnings.warn(\n",
      "/home/hice1/maleem3/.local/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:913: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home/hice1/maleem3/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/hice1/maleem3/.local/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:757: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/home/hice1/maleem3/.local/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:468: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/logging/__init__.py\", line 1100, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/logging/__init__.py\", line 943, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/logging/__init__.py\", line 678, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/logging/__init__.py\", line 368, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 711, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 215, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
      "    await result\n",
      "  File \"/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/usr/local/pace-apps/manual/packages/anaconda3/2023.03/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/scratch/642402/ipykernel_1436484/112020984.py\", line 3, in <module>\n",
      "    accuracies[model_string] = run_iteration(model_string,data_args,training_args)\n",
      "  File \"/scratch/642402/ipykernel_1436484/4251148966.py\", line 72, in run_iteration\n",
      "    logger.warning(\n",
      "Message: \"Your model seems to have been trained with labels, but they don't match the dataset: \"\n",
      "Arguments: (\"model labels: ['false', 'true'], dataset labels: ['False', 'True'].\\nIgnoring the model labels as a result.\",)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='693' max='3537' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 693/3537 00:17 < 01:10, 40.45 it/s, Epoch 0.59/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracies = dict()\n",
    "for model_string in string_to_config.keys():\n",
    "    accuracies[model_string] = run_iteration(model_string,data_args,training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "PyJhogE5iUfU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training metrics: {'train_runtime': 94.1891, 'train_samples_per_second': 300.258, 'train_steps_per_second': 37.552, 'total_flos': 950701973050368.0, 'train_loss': 0.6461303981644034, 'epoch': 3.0, 'train_samples': 9427, 'training_time': 94.3541829586029}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='409' max='409' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [409/409 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics: {'eval_loss': 0.640145480632782, 'eval_accuracy': 0.6379204892966361, 'eval_runtime': 4.9988, 'eval_samples_per_second': 654.162, 'eval_steps_per_second': 81.82, 'epoch': 3.0}\n",
      "Accuracy: 0.6379\n"
     ]
    }
   ],
   "source": [
    "metrics = train_result.metrics\n",
    "print(\"Training metrics:\", metrics)\n",
    "\n",
    "eval_metrics = trainer.evaluate(eval_dataset=eval_dataset)\n",
    "print(\"Evaluation metrics:\", eval_metrics)\n",
    "\n",
    "if 'eval_accuracy' in eval_metrics:\n",
    "    accuracy = eval_metrics['eval_accuracy']\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "PyJhogE5iUfU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training metrics: {'train_runtime': 114.2333, 'train_samples_per_second': 247.572, 'train_steps_per_second': 30.963, 'total_flos': 936577625347584.0, 'train_loss': 0.5112095499294843, 'epoch': 3.0, 'train_samples': 9427, 'training_time': 114.37978649139404}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='409' max='409' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [409/409 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation metrics: {'eval_loss': 0.7866023778915405, 'eval_accuracy': 0.7067278287461773, 'eval_runtime': 3.8374, 'eval_samples_per_second': 852.134, 'eval_steps_per_second': 106.582, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "metrics = train_result.metrics\n",
    "print(\"Training metrics:\", metrics)\n",
    "\n",
    "eval_metrics = trainer.evaluate(eval_dataset=eval_dataset)\n",
    "print(\"Evaluation metrics:\", eval_metrics)\n",
    "\n",
    "if 'eval_accuracy' in eval_metrics:\n",
    "    accuracy = eval_metrics['accuracy']\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
