# CS-7643 - Deep Learning - Summer 2024 - Final Project

# Comparative Analysis of Efficient Adapter-Based Fine-Tuning of State-of-the-Art Transformer Models
A capstone project for CS-7643, a graduate-level Deep Learning course at the Georgia Institute of Technology.

## Overview
We quantified the tradeoff between performance and training time with [adapter-based fine-tuning](https://adapterhub.ml/blog/2023/11/introducing-adapters/) of three transformer models, specifically BART, DistilBERT, and ELECTRA, on 
1. supervised binary classification tasks from the [SuperGLUE benchmark](https://super.gluebenchmark.com/)
2. supervised multi-class classification on the [Kaggle News Category dataset](https://www.kaggle.com/datasets/rmisra/news-category-dataset)